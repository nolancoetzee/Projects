{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simple Transformer - Nolan Coetzee NEED MORE DATA Model is STRONG! but only 29 paragraphs is nothing. I will now try pre-trained models like GPT2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3Vm2IcudFPrj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikeras in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.13.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikeras) (3.8.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikeras) (1.6.1)\n",
            "Requirement already satisfied: absl-py in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->scikeras) (2.1.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\nmcoe\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.2.0->scikeras) (2.2.3)\n",
            "Requirement already satisfied: rich in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->scikeras) (3.13.0)\n",
            "Requirement already satisfied: optree in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.14.0)\n",
            "Requirement already satisfied: ml-dtypes in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.5.1)\n",
            "Requirement already satisfied: packaging in c:\\users\\nmcoe\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.2.0->scikeras) (24.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nmcoe\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.2.0->scikeras) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "r8XdgmLneWRh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.1)\n",
            "Requirement already satisfied: click in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\nmcoe\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "o26cNcz1FKKi"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6VRRdofg08HJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 29 entries\n",
            "                                                Data\n",
            "0  George Washington, the first President of the ...\n",
            "1  George Washington, often called the Father of ...\n",
            "2  George Washington, revered for his leadership,...\n",
            "3  George Washington, known for his military and ...\n",
            "4  George Washington, the first President of the ...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace 'Username' with your actual Windows username\n",
        "# Assumes the file is directly on the Desktop\n",
        "file_path = r\"C:\\Users\\nmcoe\\OneDrive\\Desktop\\Data3.csv\"\n",
        "df = pd.read_csv(file_path, encoding='cp1252')  # Windows-1252\n",
        "print(f\"Loaded {len(df)} entries\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gOypMf6Y6TdI"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>George Washington, the first President of the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>George Washington, often called the Father of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>George Washington, revered for his leadership,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>George Washington, known for his military and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>George Washington, the first President of the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Data\n",
              "0  George Washington, the first President of the ...\n",
              "1  George Washington, often called the Father of ...\n",
              "2  George Washington, revered for his leadership,...\n",
              "3  George Washington, known for his military and ...\n",
              "4  George Washington, the first President of the ..."
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_sub = df[[\n",
        "    \"Data\"\n",
        "]]\n",
        "\n",
        "# Display the first few rows of the subset DataFrame\n",
        "df_sub.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZEOuAj3Ce1-M"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "^C\n",
            "Requirement already satisfied: nltk in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.1)\n",
            "Requirement already satisfied: click in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\nmcoe\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
            "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
            "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
            "   ---------- ----------------------------- 3.9/15.5 MB 26.0 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 8.9/15.5 MB 32.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 15.5/15.5 MB 29.6 MB/s eta 0:00:00\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.3\n",
            "    Uninstalling numpy-2.2.3:\n",
            "      Successfully uninstalled numpy-2.2.3\n",
            "Successfully installed numpy-1.26.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\nmcoe\\AppData\\Roaming\\Python\\Python312\\site-packages\\~umpy.libs'.\n",
            "  You can safely remove it manually.\n",
            "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\nmcoe\\AppData\\Roaming\\Python\\Python312\\site-packages\\~umpy'.\n",
            "  You can safely remove it manually.\n",
            "WARNING: Ignoring invalid distribution ~ (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (C:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.2.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
            "Downloading numpy-2.2.3-cp312-cp312-win_amd64.whl (12.6 MB)\n",
            "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
            "   ------------ --------------------------- 3.9/12.6 MB 26.2 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 11.3/12.6 MB 30.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 12.6/12.6 MB 29.3 MB/s eta 0:00:00\n",
            "Installing collected packages: numpy\n",
            "Successfully installed numpy-2.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall numpy\n",
        "!pip install numpy==1.26.4\n",
        "!pip install --user -U nltk\n",
        "!pip install --user -U numpy\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "9GIvaLVIeS6H"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                Data  \\\n",
            "0  George Washington, the first President of the ...   \n",
            "1  George Washington, often called the Father of ...   \n",
            "2  George Washington, revered for his leadership,...   \n",
            "3  George Washington, known for his military and ...   \n",
            "4  George Washington, the first President of the ...   \n",
            "\n",
            "                                              tokens  \\\n",
            "0  [George, Washington, ,, the, first, President,...   \n",
            "1  [George, Washington, ,, often, called, the, Fa...   \n",
            "2  [George, Washington, ,, revered, for, his, lea...   \n",
            "3  [George, Washington, ,, known, for, his, milit...   \n",
            "4  [George, Washington, ,, the, first, President,...   \n",
            "\n",
            "                                        sequence_ids  \n",
            "0  [1, 2, 3, 4, 5, 6, 7, 4, 8, 9, 3, 10, 11, 12, ...  \n",
            "1  [1, 2, 3, 48, 49, 4, 50, 7, 36, 51, 3, 52, 4, ...  \n",
            "2  [1, 2, 3, 69, 45, 65, 70, 3, 52, 4, 5, 6, 7, 4...  \n",
            "3  [1, 2, 3, 79, 45, 65, 80, 29, 81, 70, 3, 52, 4...  \n",
            "4  [1, 2, 3, 4, 5, 6, 7, 4, 8, 9, 3, 52, 89, 14, ...  \n",
            "The highest token in sequence_ids is: 329\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\nmcoe\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\nmcoe\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Ensure NLTK resources are downloaded\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Example DataFrame (replace with your actual df_sub)\n",
        "# df_sub = pd.DataFrame({'Data': ['George is running.', 'She walks fast, okay.']})\n",
        "\n",
        "# Tokenize each row\n",
        "def tokenize_phrase(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "df_sub['tokens'] = df_sub['Data'].apply(tokenize_phrase)\n",
        "\n",
        "# Create word-to-ID mapping\n",
        "all_words = [word for seq in df_sub['tokens'] for word in seq]\n",
        "unique_words = list(OrderedDict.fromkeys(all_words))  # Remove duplicates while preserving order\n",
        "word_to_id = {word: idx + 1 for idx, word in enumerate(unique_words)}  # IDs from 1\n",
        "vocab_size = len(unique_words) + 1  # +1 for padding token 0\n",
        "id_to_word = {idx: word for word, idx in word_to_id.items()}  # Reverse mapping\n",
        "\n",
        "# Convert tokens to ID sequences\n",
        "df_sub['sequence_ids'] = df_sub['tokens'].apply(lambda seq: [word_to_id[word] for word in seq])\n",
        "\n",
        "print(df_sub[['Data', 'tokens', 'sequence_ids']].head())\n",
        "overall_max_token = max(max(seq) for seq in df_sub['sequence_ids'])\n",
        "print(\"The highest token in sequence_ids is:\", overall_max_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'builtin_function_or_method' object has no attribute 'y'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[45], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([seq[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m df_sub[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshifted_sequence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()])  \u001b[38;5;66;03m# Shift left\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Output results\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mmax\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m.\u001b[39mX)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'y'"
          ]
        }
      ],
      "source": [
        "### WITH BEGGINING ZERO\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Determine maximum sequence length\n",
        "max_len = max(len(seq) for seq in df_sub['sequence_ids'])  # 7\n",
        "\n",
        "# Pad sequences\n",
        "def pad_sequence(seq, max_len):\n",
        "    return seq + [0] * (max_len - len(seq))\n",
        "\n",
        "df_sub['padded_sequence'] = df_sub['sequence_ids'].apply(lambda seq: pad_sequence(seq, max_len))\n",
        "\n",
        "# Add leading zero to each sequence in X\n",
        "def add_leading_zero(seq):\n",
        "    return [0] + seq[:-1]  # Shift right and add 0 at the start\n",
        "\n",
        "df_sub['shifted_sequence'] = df_sub['padded_sequence'].apply(add_leading_zero)\n",
        "\n",
        "# Create X\n",
        "X = np.array(df_sub['shifted_sequence'].tolist())\n",
        "\n",
        "# Create target sequences (shifted X)\n",
        "y = np.array([seq[1:] + [0] for seq in df_sub['shifted_sequence'].tolist()])  # Shift left\n",
        "\n",
        "# Output results\n",
        "print(\"X:\", X)\n",
        "print(\"y:\", y)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "viyTsfemxYop"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Features Shape: (20, 70)\n",
            "Testing Features Shape: (9, 70)\n",
            "Training Target Shape: (20, 70)\n",
            "Testing Target Shape: (9, 70)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#Split the dataset into training and testing sets test_size using 0.3: 70% training and 30% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "#Display the shapes of the resulting datasets\n",
        "print(\"Training Features Shape:\", X_train.shape)\n",
        "print(\"Testing Features Shape:\", X_test.shape)\n",
        "print(\"Training Target Shape:\", y_train.shape)\n",
        "print(\"Testing Target Shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "collapsed": true,
        "id": "L0z13sgsO18Y"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  0,  90,   4, ...,  40,  41,  42],\n",
              "       [  0,   1,   2, ...,   0,   0,   0],\n",
              "       [  0, 161, 162, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [  0,   2,  63, ...,   0,   0,   0],\n",
              "       [  0, 151, 152, ...,   0,   0,   0],\n",
              "       [  0,   1,   2, ...,   0,   0,   0]], shape=(20, 70))"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjf5CZ5WKfuq"
      },
      "source": [
        "Nueral Network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "collapsed": true,
        "id": "kjnyhOA1O5eE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 90,   4,   5, ...,  41,  42,   0],\n",
              "       [  1,   2,   3, ...,   0,   0,   0],\n",
              "       [161, 162, 106, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [  2,  63,  64, ...,   0,   0,   0],\n",
              "       [151, 152, 106, ...,   0,   0,   0],\n",
              "       [  1,   2,   3, ...,   0,   0,   0]], shape=(20, 70))"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.6.0-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
            "Collecting filelock (from torch)\n",
            "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\nmcoe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
            "Collecting networkx (from torch)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting setuptools (from torch)\n",
            "  Downloading setuptools-75.8.2-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting sympy==1.13.1 (from torch)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
            "Downloading torch-2.6.0-cp312-cp312-win_amd64.whl (204.1 MB)\n",
            "   ---------------------------------------- 0.0/204.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.4/204.1 MB 16.8 MB/s eta 0:00:13\n",
            "   - -------------------------------------- 9.4/204.1 MB 26.7 MB/s eta 0:00:08\n",
            "   -- ------------------------------------- 14.7/204.1 MB 25.7 MB/s eta 0:00:08\n",
            "   ---- ----------------------------------- 22.8/204.1 MB 32.1 MB/s eta 0:00:06\n",
            "   ----- ---------------------------------- 29.9/204.1 MB 33.3 MB/s eta 0:00:06\n",
            "   -------- ------------------------------- 42.2/204.1 MB 35.3 MB/s eta 0:00:05\n",
            "   ---------- ----------------------------- 51.1/204.1 MB 36.6 MB/s eta 0:00:05\n",
            "   ------------ --------------------------- 61.9/204.1 MB 38.7 MB/s eta 0:00:04\n",
            "   -------------- ------------------------- 72.6/204.1 MB 40.3 MB/s eta 0:00:04\n",
            "   ---------------- ----------------------- 83.4/204.1 MB 41.5 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 91.2/204.1 MB 41.3 MB/s eta 0:00:03\n",
            "   ------------------- ------------------- 100.9/204.1 MB 41.8 MB/s eta 0:00:03\n",
            "   --------------------- ----------------- 110.1/204.1 MB 42.1 MB/s eta 0:00:03\n",
            "   ---------------------- ---------------- 119.3/204.1 MB 42.1 MB/s eta 0:00:03\n",
            "   ------------------------ -------------- 129.2/204.1 MB 42.6 MB/s eta 0:00:02\n",
            "   -------------------------- ------------ 139.7/204.1 MB 43.1 MB/s eta 0:00:02\n",
            "   ---------------------------- ---------- 149.4/204.1 MB 43.4 MB/s eta 0:00:02\n",
            "   ------------------------------ -------- 159.1/204.1 MB 43.6 MB/s eta 0:00:02\n",
            "   -------------------------------- ------ 167.8/204.1 MB 43.8 MB/s eta 0:00:01\n",
            "   --------------------------------- ----- 176.7/204.1 MB 43.4 MB/s eta 0:00:01\n",
            "   ----------------------------------- --- 185.3/204.1 MB 43.5 MB/s eta 0:00:01\n",
            "   ------------------------------------- - 196.6/204.1 MB 43.9 MB/s eta 0:00:01\n",
            "   --------------------------------------  203.9/204.1 MB 44.0 MB/s eta 0:00:01\n",
            "   --------------------------------------  203.9/204.1 MB 44.0 MB/s eta 0:00:01\n",
            "   --------------------------------------- 204.1/204.1 MB 41.0 MB/s eta 0:00:00\n",
            "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 6.2/6.2 MB 42.0 MB/s eta 0:00:00\n",
            "Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
            "Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.7/1.7 MB 47.1 MB/s eta 0:00:00\n",
            "Downloading setuptools-75.8.2-py3-none-any.whl (1.2 MB)\n",
            "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.2/1.2 MB 31.2 MB/s eta 0:00:00\n",
            "Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
            "   ---------------------------------------- 536.2/536.2 kB 8.8 MB/s eta 0:00:00\n",
            "Installing collected packages: mpmath, sympy, setuptools, networkx, MarkupSafe, fsspec, filelock, jinja2, torch\n",
            "Successfully installed MarkupSafe-3.0.2 filelock-3.17.0 fsspec-2025.2.0 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 setuptools-75.8.2 sympy-1.13.1 torch-2.6.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~-p (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~~p (c:\\Users\\nmcoe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "pip install torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------------------------\n",
        "# Positional Encoding Module\n",
        "# -------------------------\n",
        "def get_positional_encoding(max_len, d_model):\n",
        "    \"\"\"\n",
        "    Returns a tensor of shape (1, max_len, d_model) containing the positional encodings.\n",
        "    \"\"\"\n",
        "    pe = torch.zeros(max_len, d_model)\n",
        "    position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "    pe = pe.unsqueeze(0)  # Shape: (1, max_len, d_model)\n",
        "    return pe\n",
        "\n",
        "# -------------------------\n",
        "# Transformer Model\n",
        "# -------------------------\n",
        "class SimpleTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=128, max_len=70):\n",
        "        \"\"\"\n",
        "        vocab_size: size of vocabulary (number of tokens)\n",
        "        d_model: embedding dimension and model size\n",
        "        max_len: maximum sequence length (should match your padded sequence length)\n",
        "        \"\"\"\n",
        "        super(SimpleTransformer, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.d_model = d_model\n",
        "        self.max_len = max_len\n",
        "        \n",
        "        # Embedding layer for tokens\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        \n",
        "        # Pre-computed positional encoding (registered as a buffer)\n",
        "        self.register_buffer('pe', get_positional_encoding(max_len, d_model))\n",
        "        \n",
        "        # Linear layers for computing queries, keys, and values\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        \n",
        "        # Feed-forward network\n",
        "        self.ff1 = nn.Linear(d_model, d_model)\n",
        "        self.ff2 = nn.Linear(d_model, vocab_size)\n",
        "        \n",
        "        # Layer normalization\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: tensor of shape (batch_size, seq_len) with token indices\n",
        "        \"\"\"\n",
        "        batch_size, seq_len = x.size()\n",
        "        # Lookup token embeddings and add positional encoding\n",
        "        x = self.embedding(x)  # (batch_size, seq_len, d_model)\n",
        "        x = x + self.pe[:, :seq_len, :]  # Broadcast positional encoding\n",
        "        \n",
        "        # Compute queries, keys, and values\n",
        "        Q = self.W_q(x)  # (batch_size, seq_len, d_model)\n",
        "        K = self.W_k(x)  # (batch_size, seq_len, d_model)\n",
        "        V = self.W_v(x)  # (batch_size, seq_len, d_model)\n",
        "        \n",
        "        # Compute scaled dot-product attention scores\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_model)  # (batch_size, seq_len, seq_len)\n",
        "        \n",
        "        # Create a causal mask to prevent tokens from attending to future tokens\n",
        "        mask = torch.triu(torch.ones(seq_len, seq_len, device=x.device), diagonal=1).bool()\n",
        "        scores = scores.masked_fill(mask, float('-inf'))\n",
        "        \n",
        "        # Apply softmax to get attention weights and compute the attended values\n",
        "        attn_weights = F.softmax(scores, dim=-1)\n",
        "        attended = torch.matmul(attn_weights, V)  # (batch_size, seq_len, d_model)\n",
        "        \n",
        "        # Add residual connection and apply layer normalization\n",
        "        x = self.layer_norm(x + attended)\n",
        "        \n",
        "        # Feed-forward network with ReLU activation\n",
        "        hidden = F.relu(self.ff1(x))\n",
        "        output = self.ff2(hidden)  # (batch_size, seq_len, vocab_size)\n",
        "        return output\n",
        "\n",
        "# -------------------------\n",
        "# Training Setup\n",
        "# -------------------------\n",
        "def train_model(model, optimizer, criterion, X_tensor, y_tensor, num_epochs=100, batch_size=32):\n",
        "    model.train()\n",
        "    loss_history = []\n",
        "    num_samples = X_tensor.size(0)\n",
        "    for epoch in range(num_epochs):\n",
        "        permutation = torch.randperm(num_samples)\n",
        "        epoch_loss = 0.0\n",
        "        for i in range(0, num_samples, batch_size):\n",
        "            indices = permutation[i:i + batch_size]\n",
        "            batch_X = X_tensor[indices]\n",
        "            batch_y = y_tensor[indices]\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            output = model(batch_X)  # (batch_size, seq_len, vocab_size)\n",
        "            # Reshape outputs and targets for CrossEntropyLoss:\n",
        "            loss = criterion(output.view(-1, model.vocab_size), batch_y.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        avg_loss = epoch_loss / ((num_samples // batch_size) + 1)\n",
        "        loss_history.append(avg_loss)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "    return loss_history\n",
        "\n",
        "def plot_loss(loss_history):\n",
        "    plt.plot(range(1, len(loss_history) + 1), loss_history, label='Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Over Epochs')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# -------------------------\n",
        "# Example Usage\n",
        "# -------------------------\n",
        "# Suppose you already have your training data as NumPy arrays:\n",
        "# X: shape (num_samples, seq_len), containing token IDs (integer values)\n",
        "# y: shape (num_samples, seq_len), containing target token IDs\n",
        "# For demonstration, let's create some dummy data:\n",
        "num_samples = 100\n",
        "seq_len = 50  # This should be <= max_len defined for the model\n",
        "vocab_size = 330  # Set according to your actual vocabulary size\n",
        "\n",
        "# Generate random token IDs as dummy data\n",
        "X = np.random.randint(0, vocab_size, (num_samples, seq_len))\n",
        "y = np.random.randint(0, vocab_size, (num_samples, seq_len))\n",
        "\n",
        "# Convert NumPy arrays to PyTorch tensors (use torch.long for token indices)\n",
        "X_tensor = torch.tensor(X, dtype=torch.long)\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100, Loss: 5.8284\n",
            "Epoch 2/100, Loss: 5.7763\n",
            "Epoch 3/100, Loss: 5.7394\n",
            "Epoch 4/100, Loss: 5.7218\n",
            "Epoch 5/100, Loss: 5.6877\n",
            "Epoch 6/100, Loss: 5.6711\n",
            "Epoch 7/100, Loss: 5.6325\n",
            "Epoch 8/100, Loss: 5.6033\n",
            "Epoch 9/100, Loss: 5.5610\n",
            "Epoch 10/100, Loss: 5.5140\n",
            "Epoch 11/100, Loss: 5.4887\n",
            "Epoch 12/100, Loss: 5.4123\n",
            "Epoch 13/100, Loss: 5.4033\n",
            "Epoch 14/100, Loss: 5.3689\n",
            "Epoch 15/100, Loss: 5.3172\n",
            "Epoch 16/100, Loss: 5.2974\n",
            "Epoch 17/100, Loss: 5.2228\n",
            "Epoch 18/100, Loss: 5.1951\n",
            "Epoch 19/100, Loss: 5.1322\n",
            "Epoch 20/100, Loss: 5.0072\n",
            "Epoch 21/100, Loss: 5.0472\n",
            "Epoch 22/100, Loss: 4.9496\n",
            "Epoch 23/100, Loss: 4.9000\n",
            "Epoch 24/100, Loss: 4.8447\n",
            "Epoch 25/100, Loss: 4.7797\n",
            "Epoch 26/100, Loss: 4.6660\n",
            "Epoch 27/100, Loss: 4.6397\n",
            "Epoch 28/100, Loss: 4.5264\n",
            "Epoch 29/100, Loss: 4.4101\n",
            "Epoch 30/100, Loss: 4.3607\n",
            "Epoch 31/100, Loss: 4.2799\n",
            "Epoch 32/100, Loss: 4.1514\n",
            "Epoch 33/100, Loss: 4.1745\n",
            "Epoch 34/100, Loss: 4.0473\n",
            "Epoch 35/100, Loss: 3.9624\n",
            "Epoch 36/100, Loss: 3.8702\n",
            "Epoch 37/100, Loss: 3.7985\n",
            "Epoch 38/100, Loss: 3.6931\n",
            "Epoch 39/100, Loss: 3.6383\n",
            "Epoch 40/100, Loss: 3.5910\n",
            "Epoch 41/100, Loss: 3.5136\n",
            "Epoch 42/100, Loss: 3.3851\n",
            "Epoch 43/100, Loss: 3.2960\n",
            "Epoch 44/100, Loss: 3.2062\n",
            "Epoch 45/100, Loss: 3.1217\n",
            "Epoch 46/100, Loss: 2.9858\n",
            "Epoch 47/100, Loss: 3.0199\n",
            "Epoch 48/100, Loss: 2.8554\n",
            "Epoch 49/100, Loss: 2.8470\n",
            "Epoch 50/100, Loss: 2.8279\n",
            "Epoch 51/100, Loss: 2.7349\n",
            "Epoch 52/100, Loss: 2.7416\n",
            "Epoch 53/100, Loss: 2.6962\n",
            "Epoch 54/100, Loss: 2.4937\n",
            "Epoch 55/100, Loss: 2.4732\n",
            "Epoch 56/100, Loss: 2.2818\n",
            "Epoch 57/100, Loss: 2.2344\n",
            "Epoch 58/100, Loss: 2.2997\n",
            "Epoch 59/100, Loss: 2.2316\n",
            "Epoch 60/100, Loss: 2.1322\n",
            "Epoch 61/100, Loss: 2.1244\n",
            "Epoch 62/100, Loss: 2.0393\n",
            "Epoch 63/100, Loss: 1.9275\n",
            "Epoch 64/100, Loss: 1.9456\n",
            "Epoch 65/100, Loss: 1.9110\n",
            "Epoch 66/100, Loss: 1.8345\n",
            "Epoch 67/100, Loss: 1.7536\n",
            "Epoch 68/100, Loss: 1.7829\n",
            "Epoch 69/100, Loss: 1.6140\n",
            "Epoch 70/100, Loss: 1.6230\n",
            "Epoch 71/100, Loss: 1.5397\n",
            "Epoch 72/100, Loss: 1.5425\n",
            "Epoch 73/100, Loss: 1.5553\n",
            "Epoch 74/100, Loss: 1.4250\n",
            "Epoch 75/100, Loss: 1.3509\n",
            "Epoch 76/100, Loss: 1.3565\n",
            "Epoch 77/100, Loss: 1.3456\n",
            "Epoch 78/100, Loss: 1.3416\n",
            "Epoch 79/100, Loss: 1.2245\n",
            "Epoch 80/100, Loss: 1.2057\n",
            "Epoch 81/100, Loss: 1.1196\n",
            "Epoch 82/100, Loss: 1.0989\n",
            "Epoch 83/100, Loss: 1.1020\n",
            "Epoch 84/100, Loss: 1.0486\n",
            "Epoch 85/100, Loss: 1.0449\n",
            "Epoch 86/100, Loss: 1.0462\n",
            "Epoch 87/100, Loss: 0.9363\n",
            "Epoch 88/100, Loss: 0.9375\n",
            "Epoch 89/100, Loss: 0.8898\n",
            "Epoch 90/100, Loss: 0.8524\n",
            "Epoch 91/100, Loss: 0.8508\n",
            "Epoch 92/100, Loss: 0.7455\n",
            "Epoch 93/100, Loss: 0.7543\n",
            "Epoch 94/100, Loss: 0.7221\n",
            "Epoch 95/100, Loss: 0.7117\n",
            "Epoch 96/100, Loss: 0.6830\n",
            "Epoch 97/100, Loss: 0.6381\n",
            "Epoch 98/100, Loss: 0.6192\n",
            "Epoch 99/100, Loss: 0.6389\n",
            "Epoch 100/100, Loss: 0.6219\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions: tensor([[244, 132,  36,  ...,  34, 263, 269],\n",
            "        [254, 253, 245,  ...,  33,  53,  18],\n",
            "        [137, 250,  52,  ...,  55, 138, 231],\n",
            "        ...,\n",
            "        [257,  86,  30,  ..., 130, 244, 276],\n",
            "        [ 66, 232,  89,  ..., 138, 177, 216],\n",
            "        [100,  97, 226,  ..., 194,  70,  74]])\n"
          ]
        }
      ],
      "source": [
        "#Model and Training\n",
        "# Instantiate the model, optimizer, and loss function\n",
        "model = SimpleTransformer(vocab_size=vocab_size, d_model=128, max_len=seq_len)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "loss_history = train_model(model, optimizer, criterion, X_tensor, y_tensor,\n",
        "                           num_epochs=100, batch_size=32)\n",
        "\n",
        "# Plot the loss over epochs\n",
        "plot_loss(loss_history)\n",
        "\n",
        "# -------------------------\n",
        "# Prediction Example\n",
        "# -------------------------\n",
        "def predict(model, X_tensor):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(X_tensor)  # (batch_size, seq_len, vocab_size)\n",
        "        predictions = torch.argmax(output, dim=-1)\n",
        "    return predictions\n",
        "\n",
        "# Predict on the training data (for demonstration)\n",
        "predictions = predict(model, X_tensor)\n",
        "print(\"Predictions:\", predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrbYDnJPaVD3"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated sequence (token IDs): [1, 2, 266, 30, 35, 230, 205, 86, 127, 139, 205, 310, 321, 216, 320, 228, 153, 263, 30, 101, 14, 244]\n",
            "Word sequence: George Washington leading later government planter further leave stable central further immeasurable ideals understood term excessive were took later peaceful in place\n"
          ]
        }
      ],
      "source": [
        "# Generation loop using the PyTorch model\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "max_tokens = 20\n",
        "# Get the end token ID (using '.' as the end token)\n",
        "end_token = word_to_id.get('.', vocab_size - 1)  # Adjust if needed\n",
        "initial_tokens = [word_to_id.get(word, 0) for word in ['George', 'Washington']]\n",
        "generated_tokens = initial_tokens.copy()\n",
        "\n",
        "# Initialize context: pad on the left if the context is shorter than max_len\n",
        "if len(initial_tokens) < seq_len:\n",
        "    padded_context = [0] * (seq_len - len(initial_tokens)) + initial_tokens\n",
        "else:\n",
        "    padded_context = initial_tokens[-seq_len:]\n",
        "\n",
        "# Autoregressive generation loop\n",
        "for _ in range(max_tokens):\n",
        "    # Prepare input: a tensor of shape (1, seq_len) with our token IDs\n",
        "    input_tensor = torch.tensor([padded_context], dtype=torch.long)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        # Forward pass: output shape -> (1, seq_len, vocab_size)\n",
        "        output = model(input_tensor)\n",
        "    \n",
        "    # Get the probabilities/logits of the last time step and choose the token with maximum score\n",
        "    last_logits = output[0, -1, :]  # shape: (vocab_size,)\n",
        "    predicted_token = torch.argmax(last_logits).item()\n",
        "    \n",
        "    generated_tokens.append(predicted_token)\n",
        "    \n",
        "    # Update context: remove the oldest token and append the predicted token\n",
        "    padded_context = padded_context[1:] + [predicted_token]\n",
        "    \n",
        "    # If the predicted token is the end token, break early\n",
        "    if predicted_token == end_token:\n",
        "        break\n",
        "\n",
        "# Convert the generated tokens back into words using id_to_word mapping\n",
        "word_sequence = ' '.join(id_to_word.get(token, \"UNKNOWN\") for token in generated_tokens)\n",
        "print(f\"Generated sequence (token IDs): {generated_tokens}\")\n",
        "print(f\"Word sequence: {word_sequence}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
